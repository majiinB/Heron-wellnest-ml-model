{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47361cbd",
   "metadata": {},
   "source": [
    "# **Synthetic Data Generation**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b09501",
   "metadata": {},
   "source": [
    "# Basis for Synthetic Dataset Rules\n",
    "\n",
    "This synthetic dataset generator simulates student well-being classifications based on heuristic rules, enforced class distributions, and controlled outliers. These design choices mirror real-world conditions where mental health data is often noisy, imbalanced, and influenced by overlapping emotional states.\n",
    "\n",
    "---\n",
    "## 1. High-level assumptions\n",
    "- Each row = a single daily log for a user (one user-day).\n",
    "- Every user must choose 1–3 moods/day (so at least one mood bit = 1).\n",
    "- Journaling (free-text) is optional per day; if no journal → all `p_* = 0.0`.\n",
    "- Gratitude entry is optional and recorded as a binary flag.\n",
    "- `WellbeingClass` is the label of record, derived primarily from moods, secondarily modulated by journaling probabilities and gratitude.\n",
    "- There are 4 WellbeingClasses: `InCrisis`, `Struggling`, `Excelling`, `Thriving`.\n",
    "\n",
    "---\n",
    "## 2. Target class-level population distribution\n",
    "These percentages reflect a plausible population-level mix for an app balancing support vs normal users. (adjust based on CGCS expectations).\n",
    "\n",
    "Based on research into the prevalence of mental health conditions among Filipino university students and young adults, this model proposes a realistic and balanced distribution for the synthetic dataset. Unlike earlier drafts, **this version removes the \"Surviving\" category** to better align with the finalized heuristic rules in the generator.  \n",
    "\n",
    "Instead of five classes, we now use four: **Excelling, Thriving, Struggling, and In Crisis.** This structure matches the logic applied in the data generator and avoids artificial overlap between \"Struggling\" and \"Surviving.\"\n",
    "\n",
    "### Final Distribution\n",
    "* **Excelling:** **3–5%**\n",
    "* **Thriving:** **7–10%**\n",
    "* **Struggling:** **25–30%**\n",
    "* **In Crisis:** **15–20%**\n",
    "\n",
    "### Rationale and Research-Backed Justification\n",
    "This model maintains evidence-based prevalence rates while making the class taxonomy cleaner and more practical for ML training.\n",
    "\n",
    "- **Excelling (3–5%) & Thriving (7–10%)**  \n",
    "  These categories correspond to the \"Flourishing\" group in the AXA Mind Health Report, which found that only **15%** of young people in Asia are flourishing. We split this into two tiers:\n",
    "  - *Excelling* → the true high-performers, a smaller share (3–5%).  \n",
    "  - *Thriving* → doing very well but not at the extreme top (7–10%).\n",
    "\n",
    "- **Struggling (25–30%)**  \n",
    "  Supported by studies like Mendoza et al. (2021), which showed **over 23%** of Filipino university students experienced severe anxiety symptoms. This category captures those with significant distress but not at crisis level.\n",
    "\n",
    "- **In Crisis (15–20%)**  \n",
    "  Higher than some global estimates, but justified by local data. Tria (2015) found **24% prevalence of suicide ideation** among Manila university students. This category represents both acute suicidal risk and severe clinical distress.\n",
    "\n",
    "### Why \"Surviving\" Was Removed\n",
    "\n",
    "- **Overlap with Struggling:** In practice, the \"Surviving\" category captured milder distress, but the boundary between \"Surviving\" and \"Struggling\" was blurry. This weakened class separation.  \n",
    "- **Heuristic Consistency:** The current labeling rules classify such cases under **Struggling** (moderate anxiety or depression), making a separate category redundant.  \n",
    "- **Simpler, Cleaner Taxonomy:** By reducing to four classes, the dataset avoids artificial middle-ground states and ensures each label has clear, actionable meaning for training and downstream interpretation.\n",
    "\n",
    "### References\n",
    "- **Mendoza, N. B., et al. (2021).** Mental Health Status and Help-Seeking Behavior of Filipino University Students During the COVID-19 Pandemic. *Transactions of the National Academy of Science and Technology, 43*(2).  \n",
    "- **Tria, A. (2015).** A Multivariate Analysis of Suicide Ideation Among University Students in the Philippines. *Asia Pacific Social Science Review, 15*(1), 1–13.  \n",
    "- **AXA. (2022).** *[AXA Mind Health Report](https://www.axa.com.ph/multimedia/newsroom/gen-z-pinoys-have-more-mind-health-conditions)*  \n",
    "- **AXA. (2024).** *[AXA Mind Health Report: Higher work stress seen among Millennials and Gen Zs](https://pop.inquirer.net/369115/axa-mind-health-report-higher-work-stress-seen-among-millennials-and-gen-zs)*  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Mood sets & mapping (16 moods → 4 classes)\n",
    "Each class has exactly 4 mapped moods.\n",
    "- **InCrisis:** `Depressed`, `Sad`, `Exhausted`, `Hopeless`,\n",
    "- **Struggling:** `Anxious`, `Angry`, `Stressed`, `Restless`,\n",
    "- **Thriving:** `Calm`, `Relaxed`, `Peaceful`, `Content`,\n",
    "- **Excelling:** `Happy`, `Energized`, `Excited`, `Motivated`,\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Mood selection rules (per row)\n",
    "- First sample `WellbeingClass` according to distribution in (2).\n",
    "- Then choose a number of moods `k ∈ {1,2,3}`:\n",
    "  - Probability of `k`: P(1)=0.6, P(2)=0.3, P(3)=0.1 (adjusta base on CGCS).\n",
    "- Choose k moods preferentially:\n",
    "- At least **70%** of selections must be from the chosen class’s 4 mapped moods.\n",
    "- Remaining selections (if k>1) may be:\n",
    "  - Same-class co-occurring mood (strong preference), or\n",
    "  - With small probability (10–15%) a mood from adjacent severity class (e.g., Struggling ↔ Stable), modeling mixed-state days.\n",
    "- Ensure no row has zero moods.\n",
    "\n",
    "Example (InCrisis day, k=2): pick `Sad` and `Depressed` (both in InCrisis) with high probability; or `Sad` + `Hopeless`.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Journaling probability behaviour (per row)\n",
    "Journaling probability is conditional on wellbeing class (people in worse states may journal more or less depending on your assumption — choose one; below is a suggested realistic pattern):\n",
    "\n",
    "- InCrisis: 60% chance to journal\n",
    "- Struggling: 50%\n",
    "- Thriving: 40%\n",
    "- Excelling: 35%\n",
    "\n",
    "If journaling = False → set p_anxiety = p_normal = p_depression = p_suicidal = p_stress = 0.0.\n",
    "\n",
    "If journaling = True → generate a probability vector p = (p_anxiety, p_normal, p_depression, p_suicidal, p_stress) sampled from a Dirichlet-like mechanism tuned per class (details below).\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Generating NLP probability vectors (conditional on journaling & class)\n",
    "Use class-specific Dirichlet / Beta mixtures to produce realistic, soft probabilities that generally peak at the expected class but allow uncertainty.\n",
    "\n",
    "### **a. Dirichlet centers (example - mean preference per class)**\n",
    "Normalized center vectors `μ_class` (sums to 1):\n",
    "- InCrisis μ = [p_anxiety=0.30, p_normal=0.05, p_depression=0.45, p_suicidal=0.15, p_stress=0.05]\n",
    "- Struggling μ = [0.25, 0.10, 0.40, 0.02, 0.23]\n",
    "- Thriving μ = [0.05, 0.75, 0.05, 0.00, 0.15]\n",
    "- Excelling μ = [0.02, 0.85, 0.01, 0.00, 0.12]\n",
    "\n",
    ">(We can change weights; ensure suicidal probabilities are low except for InCrisis.)\n",
    "\n",
    "### **b. Concentration parameter (controls spread)**\n",
    "- Use Dirichlet concentration `α = μ * s`. Pick s (scalar) to control certainty:\n",
    "  - For more peaked distributions (less noise), use `s = 50`.\n",
    "  - For more variance, `s = 10`.\n",
    "- Suggested: `s = 25` for balanced realism (not too deterministic).\n",
    "\n",
    "### **c. Sampling process**\n",
    "- Sample `p_vec ~ Dirichlet(α = μ * s)` → yields 5 probabilities summing to 1.\n",
    "- Optionally scale the vector by the model confidence: produce `p_*` as the sampled vector directly if you want normalized probabilities. If you prefer absolute model confidences with possible low overall confidence, you can multiply the sampled vector by a scalar `c` drawn from Beta(α=2, β=8) to create overall lower confidences (e.g., `p_vec_scaled = c * p_vec`), but ensure semantics: if you want `p_*` to be model logits normalized among classes then no scaling — keep as sum=1.\n",
    "\n",
    "### **d. When to set zeros or small values**\n",
    "- If journaling detected but the journal is neutral: the Dirichlet center for `Thriving` or `Excelling` handles that with high p_normal.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Gratitude flag probabilities (conditional on class)\n",
    "Make gratitude more likely in positive states but still possible in all.\n",
    "- P(gratitude=1 | Excelling) = 0.80\n",
    "- P(gratitude=1 | Thriving) = 0.60\n",
    "- P(gratitude=1 | Struggling) = 0.35\n",
    "- P(gratitude=1 | InCrisis) = 0.20\n",
    "> (If a user wrote a gratitude entry, the flag is 1 regardless of length.)\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Label consistency & conflict resolution\n",
    "Primary driver of `WellbeingClass` should be the mood selection (required input). But journaling and gratitude can nudge or validate labels. Implement rule-based checks:\n",
    "\n",
    "- If moods clearly map to class X (≥60% of chosen moods from class X), set `WellbeingClass` = X.\n",
    "- Edge cases:\n",
    "  - If moods are mixed across classes (e.g., 1 InCrisis + 1 Excelling) then:\n",
    "    - Tie-break by severity bias (prefer worse class) OR\n",
    "    - Use a small scoring function:\n",
    "      - Score[class] = sum(weights of chosen moods mapped to class) + `logit_journal_score` + `gratitude_bonus`\n",
    "    - `logit_journal_score` = +2 if `p_{class}` is top probability and > 0.4; else 0.\n",
    "    - `gratitude_bonus` = +1 to positive classes if gratitude=1.\n",
    "- **For safety:** if `p_suicidal` > 0.5 and/or `Hopeless` or `Depressed` selected, force `WellbeingClass = InCrisis` (for synthetic realism and triage logic).\n",
    "\n",
    "> Document the exact deterministic tie-breaking rule to make the dataset audit-friendly.\n",
    "\n",
    "--- \n",
    "\n",
    "## 9. Generation algorithm (pseudocode)\n",
    "1. Sample WellbeingClass per distribution (step 2).\n",
    "2. Sample k moods (1–3) per (4); pick moods with class bias and small cross-class probability.\n",
    "3. Determine journaling flag from step 5.\n",
    "  - If False → set all p_* = 0.0.\n",
    "  - If True → sample p_vec from Dirichlet centered on class mu (step 6).\n",
    "4. Determine gratitude flag conditional on class (step 7).\n",
    "5. Apply conflict resolution to set final WellbeingClass if you prefer mood-first then journal-second; otherwise keep the sampled class (but document which you used).\n",
    "6. Output the row.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Validation checks & metrics\n",
    "This are the things to include in the approval report to show the synthetic data is realistic and internally consistent.\n",
    "- No zero-mood rows: assert sum(mood_cols) >= 1 for all rows.\n",
    "- Journaling nulls match p_ zeros*: rows with journaling=False must have all p_* == 0.\n",
    "- Distribution check: empirical % of each WellbeingClass matches target distribution ± tolerance (e.g., ±2%).\n",
    "- Gratitude by class: table of P(gratitude=1 | class) vs target.\n",
    "- Confusion matrix (mood→label): measure how often moods imply the label (should be >90% if mood-driven).\n",
    "- p_ summary by class*: report means/medians for each p_* grouped by class — should show expected peaks.\n",
    "- Co-occurrence rates: e.g., P(Depressed & Hopeless | InCrisis) should be high (report actual).\n",
    "- Edge-case rules applied: count rows where suicidal probability > 0.5 and verify class = InCrisis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291d230",
   "metadata": {},
   "source": [
    "## **Setup & Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b887fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118c8ca5",
   "metadata": {},
   "source": [
    "---\n",
    "## **Configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a971417",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/classification/synthetic_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9069e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOOD_POOLS = {\n",
    "    \"InCrisis\": [\"Depressed\", \"Sad\", \"Exhausted\", \"Hopeless\"],\n",
    "    \"Struggling\": [\"Anxious\", \"Angry\", \"Stressed\", \"Restless\"],\n",
    "    \"Thriving\": [\"Calm\", \"Relaxed\", \"Peaceful\", \"Content\"],\n",
    "    \"Excelling\": [\"Happy\", \"Energized\", \"Excited\", \"Motivated\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32236813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build reverse map automatically\n",
    "MOOD_CLASS_MAP = {mood: cls for cls, moods in MOOD_POOLS.items() for mood in moods}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c584f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MOODS = sum(MOOD_POOLS.values(), [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd8428",
   "metadata": {},
   "source": [
    "---\n",
    "## **Data Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c4c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_independent_mood(\n",
    "    n=1000,\n",
    "    save_path=\"synthetic_dataset.csv\",\n",
    "    outlier_ratio=0.02,\n",
    "    gratitude_prob=0.6,   # probability of a gratitude entry\n",
    "    mood_only_ratio=0.1,  # fraction of rows that are mood-only (no journal text)\n",
    "    distribution={\n",
    "        \"Excelling\": (0.03, 0.05),\n",
    "        \"Thriving\": (0.07, 0.10),\n",
    "        \"Struggling\": (0.25, 0.30),\n",
    "        \"InCrisis\": (0.15, 0.20),\n",
    "    },\n",
    "    journal_min_fraction=0.6,  # minimum fraction of rows per class that must have journal probabilities (not mood-only)\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    # --- Step 1: Generate oversampled rows ---\n",
    "    # Oversample to ensure enough data after enforcing class distribution\n",
    "    for _ in range(n * 2):\n",
    "        # Decide if this row is mood-only\n",
    "        is_mood_only = np.random.rand() < mood_only_ratio\n",
    "\n",
    "        # --- Step 2: Generate journal probabilities (only for journal entries) ---\n",
    "        if is_mood_only:\n",
    "            # Mood-only row -> journal probabilities set to zero\n",
    "            p_anx = p_norm = p_dep = p_sui = p_str = 0.0\n",
    "        else:\n",
    "            # Generate random probabilities for journal features\n",
    "            scores = np.random.rand(5)\n",
    "            probs = scores / scores.sum()  # normalize to sum=1\n",
    "            p_anx, p_norm, p_dep, p_sui, p_str = probs\n",
    "\n",
    "        # --- Step 3: Generate moods independently ---\n",
    "        # Randomly pick 1-3 moods from all moods\n",
    "        num_moods = np.random.randint(1, 4)\n",
    "        chosen_moods = np.random.choice(ALL_MOODS, size=num_moods, replace=False)\n",
    "\n",
    "        # --- Step 4: Assign preliminary label based on journal probabilities ---\n",
    "        if not is_mood_only:\n",
    "            if (p_dep > 0.5 and p_sui > 0.3) or (p_anx > 0.4 and p_str > 0.4):\n",
    "                label = \"InCrisis\"\n",
    "            elif p_dep > 0.3 or p_anx > 0.3:\n",
    "                label = \"Struggling\"\n",
    "            elif p_norm > 0.7 and max(p_anx, p_dep, p_sui, p_str) < 0.1:\n",
    "                label = \"Excelling\"\n",
    "            elif p_norm > 0.5 and max(p_anx, p_dep, p_sui, p_str) < 0.2:\n",
    "                label = \"Thriving\"\n",
    "            else:\n",
    "                label = \"Struggling\"\n",
    "        else:\n",
    "            # Mood-only row -> initial label will be determined by moods\n",
    "            label = None\n",
    "\n",
    "        # --- Step 5: Adjust label based on moods ---\n",
    "        # If moods indicate a worse class than the journal, upgrade accordingly\n",
    "        mood_labels = [MOOD_CLASS_MAP[m] for m in chosen_moods]\n",
    "        if \"InCrisis\" in mood_labels:\n",
    "            label = \"InCrisis\"\n",
    "        elif \"Struggling\" in mood_labels and (label is None or label != \"InCrisis\"):\n",
    "            label = \"Struggling\"\n",
    "        elif \"Thriving\" in mood_labels and (label is None):\n",
    "            label = \"Thriving\"\n",
    "        elif label is None:\n",
    "            label = \"Excelling\"\n",
    "\n",
    "        # --- Step 6: One-hot encode moods ---\n",
    "        mood_encoding = {m: (1 if m in chosen_moods else 0) for m in ALL_MOODS}\n",
    "\n",
    "        # --- Step 7: Add gratitude flag ---\n",
    "        gratitude_flag = np.random.choice([0, 1], p=[1 - gratitude_prob, gratitude_prob])\n",
    "\n",
    "        # --- Step 8: Combine all features into a row ---\n",
    "        row = {\n",
    "            \"p_anxiety\": p_anx,\n",
    "            \"p_normal\": p_norm,\n",
    "            \"p_depression\": p_dep,\n",
    "            \"p_suicidal\": p_sui,\n",
    "            \"p_stress\": p_str,\n",
    "            \"gratitude_flag\": gratitude_flag,\n",
    "            \"WellbeingClass\": label\n",
    "        }\n",
    "        row.update(mood_encoding)\n",
    "        rows.append(row)\n",
    "\n",
    "    # --- Step 9: Convert to DataFrame ---\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # --- Step 10: Enforce target distribution ---\n",
    "    final_rows = []\n",
    "    for label, (low, high) in distribution.items():\n",
    "        target_frac = np.random.uniform(low, high)\n",
    "        target_n = int(n * target_frac)\n",
    "\n",
    "        subset = df[df[\"WellbeingClass\"] == label]\n",
    "        # Ensure a minimum fraction of sampled rows contain journal probabilities (i.e., not mood-only)\n",
    "        if len(subset) == 0:\n",
    "            sampled = subset\n",
    "        else:\n",
    "            # split subset into journal rows and mood-only rows\n",
    "            journal_mask = (subset[\"p_anxiety\"] > 0) | (subset[\"p_normal\"] > 0)\n",
    "            journal_rows = subset[journal_mask]\n",
    "            mood_only_rows = subset[~journal_mask]\n",
    "\n",
    "            min_journal_needed = int(np.ceil(target_n * journal_min_fraction))\n",
    "            # clamp to available\n",
    "            n_journal_to_take = min(len(journal_rows), min_journal_needed)\n",
    "            n_remaining = target_n - n_journal_to_take\n",
    "\n",
    "            chosen_journal = pd.DataFrame()\n",
    "            chosen_mood_only = pd.DataFrame()\n",
    "\n",
    "            if n_journal_to_take > 0:\n",
    "                replace_journal = len(journal_rows) < n_journal_to_take\n",
    "                chosen_journal = journal_rows.sample(n=n_journal_to_take, replace=replace_journal, random_state=42)\n",
    "\n",
    "            if n_remaining > 0:\n",
    "                # fill remaining from mood-only first, then journal if needed\n",
    "                if len(mood_only_rows) >= n_remaining:\n",
    "                    chosen_mood_only = mood_only_rows.sample(n=n_remaining, replace=False, random_state=42)\n",
    "                else:\n",
    "                    chosen_mood_only = mood_only_rows\n",
    "                    still_needed = n_remaining - len(chosen_mood_only)\n",
    "                    if len(journal_rows) > n_journal_to_take:\n",
    "                        extra_from_journal = journal_rows.drop(chosen_journal.index, errors=\"ignore\")\n",
    "                        replace_extra = len(extra_from_journal) < still_needed\n",
    "                        extra = extra_from_journal.sample(n=still_needed, replace=replace_extra, random_state=42)\n",
    "                        chosen_journal = pd.concat([chosen_journal, extra])\n",
    "\n",
    "            sampled = pd.concat([chosen_journal, chosen_mood_only])\n",
    "            # if still short (very small subsets), allow oversampling from subset\n",
    "            if len(sampled) < target_n:\n",
    "                needed = target_n - len(sampled)\n",
    "                extra = subset.sample(n=needed, replace=True, random_state=42)\n",
    "                sampled = pd.concat([sampled, extra])\n",
    "\n",
    "        final_rows.append(sampled)\n",
    "\n",
    "    df = pd.concat(final_rows).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # --- Step 11: Inject outliers into journal probabilities ---\n",
    "    journal_rows = df[(df[\"p_anxiety\"] > 0) | (df[\"p_normal\"] > 0)].index\n",
    "    n_outliers_probs = int(len(journal_rows) * outlier_ratio)\n",
    "    outlier_indices_probs = np.random.choice(journal_rows, size=n_outliers_probs, replace=False)\n",
    "\n",
    "    for idx in outlier_indices_probs:\n",
    "        probs = df.loc[idx, [\"p_anxiety\", \"p_normal\", \"p_depression\", \"p_suicidal\", \"p_stress\"]].values\n",
    "        noisy = probs + np.random.normal(0, 0.5, size=5)\n",
    "        noisy = np.clip(noisy, 0, None)  # prevent negatives\n",
    "        if noisy.sum() == 0:\n",
    "            noisy = np.random.rand(5)  # fallback if all clipped\n",
    "        noisy = noisy / noisy.sum()\n",
    "        df.loc[idx, [\"p_anxiety\", \"p_normal\", \"p_depression\", \"p_suicidal\", \"p_stress\"]] = noisy\n",
    "\n",
    "    # --- Step 12: Inject outliers into moods ---\n",
    "    n_outliers_moods = int(len(df) * outlier_ratio)\n",
    "    outlier_indices_moods = np.random.choice(df.index, size=n_outliers_moods, replace=False)\n",
    "    for idx in outlier_indices_moods:\n",
    "        mood_to_flip = np.random.choice(ALL_MOODS)\n",
    "        df.at[idx, mood_to_flip] = 1 - df.at[idx, mood_to_flip]  # flip 0→1 or 1→0\n",
    "\n",
    "    # --- Step 13: Save dataset ---\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"✅ Dataset generated and saved to {save_path}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443769ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset generated and saved to ../../data/classification/synthetic_dataset.csv\n",
      "   p_anxiety  p_normal  p_depression  p_suicidal  p_stress  gratitude_flag  \\\n",
      "0   0.000000  0.000000      0.000000    0.000000  0.000000               1   \n",
      "1   0.000000  0.000000      0.000000    0.000000  0.000000               0   \n",
      "2   0.171911  0.012415      0.095732    0.359229  0.360712               1   \n",
      "3   0.000000  0.000000      0.000000    0.000000  0.000000               0   \n",
      "4   0.000000  0.000000      0.000000    0.000000  0.000000               1   \n",
      "\n",
      "  WellbeingClass  Depressed  Sad  Exhausted  ...  Stressed  Restless  Calm  \\\n",
      "0       InCrisis          0    0          1  ...         0         0     0   \n",
      "1       InCrisis          0    0          1  ...         0         0     0   \n",
      "2       InCrisis          1    0          0  ...         0         0     0   \n",
      "3      Excelling          0    0          0  ...         0         0     0   \n",
      "4       InCrisis          0    0          1  ...         0         0     0   \n",
      "\n",
      "   Relaxed  Peaceful  Content  Happy  Energized  Excited  Motivated  \n",
      "0        0         0        1      1          0        0          0  \n",
      "1        0         0        0      0          0        0          0  \n",
      "2        1         0        1      0          0        0          0  \n",
      "3        0         0        0      0          1        0          1  \n",
      "4        0         0        1      0          1        0          0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example/demo usage when running this notebook as a script\n",
    "    df = generate_sample_independent_mood(5000, save_path=DATA_PATH)\n",
    "    print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heron-wellnest-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
